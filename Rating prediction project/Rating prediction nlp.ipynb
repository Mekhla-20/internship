{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8452e501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import power_transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve,auc,classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63a25fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import  stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be4b022e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Super!</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          Review  Rating\n",
       "0           0    Nice product     4.0\n",
       "1           1     Good choice     4.0\n",
       "2           2  Classy product     5.0\n",
       "3           3        Moderate     5.0\n",
       "4           4          Super!     4.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('review.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5461e833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5474 entries, 0 to 5473\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Review  5467 non-null   object \n",
      " 1   Rating  5467 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 85.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cf6e87",
   "metadata": {},
   "source": [
    "We can delete unnamed: 0 column as it is just an indexing column which is not required in analysis. We will also check the values of rating column as all the values should be in integer form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c793a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be4f9ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    3607\n",
       "4.0    1453\n",
       "3.0     319\n",
       "2.0      88\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754b4dde",
   "metadata": {},
   "source": [
    "## data balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "327c604d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    3607\n",
       "4.0    3607\n",
       "3.0    3607\n",
       "2.0    3607\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "rate5=df[df.Rating==5]\n",
    "rate4=df[df.Rating==4]\n",
    "rate3=df[df.Rating==3]\n",
    "rate2=df[df.Rating==2]\n",
    "rate4_upsampled=resample(rate4,replace=True,n_samples=len(rate5),random_state=27)\n",
    "rate3_upsampled=resample(rate3,replace=True,n_samples=len(rate5),random_state=27)\n",
    "rate2_upsampled=resample(rate2,replace=True,n_samples=len(rate5),random_state=27)\n",
    "df_up=pd.concat([rate5,rate4_upsampled,rate3_upsampled,rate2_upsampled])\n",
    "df_up['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec57d6ab",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70088759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting all the reviews to lower case so thats its easy to analyse them.\n",
    "df_up['Review']=df_up['Review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bd805dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing email address,links, phone numbers, any sort of numbers and currency as they are not a review\n",
    "df_up['Review'] = df_up['Review'].str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$','emailid')\n",
    "df_up['Review'] = df_up['Review'].str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$','link')\n",
    "df_up['Review'] = df_up['Review'].str.replace(r'Â£|\\$', 'currency')   \n",
    "df_up['Review'] = df_up['Review'].str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$','phno')\n",
    "df_up['Review'] = df_up['Review'].str.replace(r'\\d+(\\.\\d+)?', 'numbr')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d6ca0541",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review']=df['Review'].apply(lambda x: np.str_(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b2d56563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing punctuations\n",
    "df_up['Review'] = df_up['Review'].apply(lambda x: ' '.join(\n",
    "    term for term in str(x).split() if term not in string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2afa76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stop words\n",
    "sw = set(stopwords.words('english') + ['u', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure'])\n",
    "df_up['Review'] = df_up['Review'].apply(lambda x: ' '.join(\n",
    "    term for term in str(x).split() if term not in sw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3296bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=WordNetLemmatizer()\n",
    "df_up['Review'] = df_up['Review'].apply(lambda x: ' '.join(\n",
    " lm.lemmatize(t) for t in str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b99d418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text into vectors using TFIDF\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features = 10000, stop_words='english')\n",
    "x = tfidf.fit_transform(df_up['Review'].apply(lambda x: np.str_(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "17413493",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_up['Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ab58eb",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8469c7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Best accuracy at random state- 0\n",
      "\n",
      "Train Accuracy-  36.5\n",
      "\n",
      "Test Accuracy-  36.1\n",
      "\n",
      "\n",
      " Best accuracy at random state- 1\n",
      "\n",
      "Train Accuracy-  36.6\n",
      "\n",
      "Test Accuracy-  35.6\n",
      "\n",
      "\n",
      " Best accuracy at random state- 2\n",
      "\n",
      "Train Accuracy-  36.7\n",
      "\n",
      "Test Accuracy-  35.5\n",
      "\n",
      "\n",
      " Best accuracy at random state- 3\n",
      "\n",
      "Train Accuracy-  36.5\n",
      "\n",
      "Test Accuracy-  36.1\n",
      "\n",
      "\n",
      " Best accuracy at random state- 4\n",
      "\n",
      "Train Accuracy-  36.6\n",
      "\n",
      "Test Accuracy-  36.0\n",
      "\n",
      "\n",
      " Best accuracy at random state- 5\n",
      "\n",
      "Train Accuracy-  36.5\n",
      "\n",
      "Test Accuracy-  36.2\n",
      "\n",
      "\n",
      " Best accuracy at random state- 6\n",
      "\n",
      "Train Accuracy-  36.4\n",
      "\n",
      "Test Accuracy-  36.7\n",
      "\n",
      "\n",
      " Best accuracy at random state- 7\n",
      "\n",
      "Train Accuracy-  37.1\n",
      "\n",
      "Test Accuracy-  33.7\n",
      "\n",
      "\n",
      " Best accuracy at random state- 8\n",
      "\n",
      "Train Accuracy-  36.5\n",
      "\n",
      "Test Accuracy-  36.2\n",
      "\n",
      "\n",
      " Best accuracy at random state- 9\n",
      "\n",
      "Train Accuracy-  36.6\n",
      "\n",
      "Test Accuracy-  36.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "max_ac=0\n",
    "randomState=0\n",
    "lr=LogisticRegression()\n",
    "for i in range(10):\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=i,test_size=0.20)\n",
    "    lr.fit(x_train,y_train)\n",
    "    pred_train=lr.predict(x_train)\n",
    "    pred_test=lr.predict(x_test)\n",
    "    if round(accuracy_score(y_train,pred_train)*100,1)==round(accuracy_score(y_test,pred_test)*100,1):\n",
    "        print(\"\\n\\nAt random state:\",i)\n",
    "        print(\"\\nTrain Accuracy- \",round(accuracy_score(y_train,pred_train)*100,1))\n",
    "        print(\"\\nTest Accuracy- \",round(accuracy_score(y_test,pred_test)*100,1))\n",
    "        if round(accuracy_score(y_test,pred_test)*100,1)>max_ac:\n",
    "            randomState=i\n",
    "            max_ac=round(accuracy_score(y_test,pred_test)*100,1)\n",
    "    print(\"\\n\\n Best accuracy at random state-\",i)\n",
    "    print(\"\\nTrain Accuracy- \",round(accuracy_score(y_train,pred_train)*100,1))\n",
    "    print(\"\\nTest Accuracy- \",round(accuracy_score(y_test,pred_test)*100,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdfad43",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b6a57ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train accuracy- 36.6\n",
      "\n",
      "test accuracy- 36.0\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=9,test_size=0.20)\n",
    "lr.fit(x_train,y_train)\n",
    "pred_train=lr.predict(x_train)\n",
    "pred_test=lr.predict(x_test)\n",
    "train_accuracy=round(accuracy_score(y_train,pred_train)*100,1)\n",
    "test_accuracy=round(accuracy_score(y_test,pred_test)*100,1)\n",
    "print(\"\\ntrain accuracy-\",train_accuracy)\n",
    "print(\"\\ntest accuracy-\",test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c7a0bc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation score is- 36.42223454394233\n",
      "accuracy score for logistic regression model is- 36.0\n"
     ]
    }
   ],
   "source": [
    "# CV Score\n",
    "cv_score_best=cross_val_score(lr,x,y,cv=4).mean()*100\n",
    "print(\"cross validation score is-\",cv_score_best)\n",
    "print(\"accuracy score for logistic regression model is-\",test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "90e32c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       747\n",
      "         3.0       0.00      0.00      0.00       739\n",
      "         4.0       0.28      1.00      0.44       729\n",
      "         5.0       1.00      0.46      0.63       671\n",
      "\n",
      "    accuracy                           0.36      2886\n",
      "   macro avg       0.32      0.37      0.27      2886\n",
      "weighted avg       0.30      0.36      0.26      2886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b63af9f",
   "metadata": {},
   "source": [
    "## Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b2ccf4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc train 36.4\n",
      "acc test 36.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt=DecisionTreeClassifier()\n",
    "dt.fit(x_train,y_train)\n",
    "dt_pred_train=dt.predict(x_train)\n",
    "dt_pred_test=dt.predict(x_test)\n",
    "dt_acc_train=round(accuracy_score(y_train,dt_pred_train)*100,1)\n",
    "dt_acc_test=round(accuracy_score(y_test,dt_pred_test)*100,1)\n",
    "print(\"acc train\",dt_acc_train)\n",
    "print(\"acc test\",dt_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "be9b02d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation score is- 36.42223454394233\n",
      "accuracy score for decision tree model is- 36.6\n"
     ]
    }
   ],
   "source": [
    "# CV Score\n",
    "cv_score_best_dt=cross_val_score(dt,x,y,cv=4).mean()*100\n",
    "print(\"cross validation score is-\",cv_score_best)\n",
    "print(\"accuracy score for decision tree model is-\",dt_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "31928c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       737\n",
      "         3.0       0.00      0.00      0.00       688\n",
      "         4.0       0.25      0.89      0.39       713\n",
      "         5.0       0.25      0.10      0.15       748\n",
      "\n",
      "    accuracy                           0.25      2886\n",
      "   macro avg       0.13      0.25      0.13      2886\n",
      "weighted avg       0.13      0.25      0.13      2886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "print(classification_report(y_test, dt_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0dc7fb",
   "metadata": {},
   "source": [
    "## Knn Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ea403250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Accuracy-  36.6\n",
      "\n",
      "Test Accuracy-  35.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier()\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=1,test_size=0.20)\n",
    "knn.fit(x_train,y_train)\n",
    "pred_train=knn.predict(x_train)\n",
    "pred_test=knn.predict(x_test)\n",
    "knn_train_acc=round(accuracy_score(y_train,pred_train)*100,1)\n",
    "knn_test_acc=round(accuracy_score(y_test,pred_test)*100,1)\n",
    "print(\"\\nTrain Accuracy- \",knn_train_acc)\n",
    "print(\"\\nTest Accuracy- \",knn_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "17fa901f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation score is- 36.37056541019955\n",
      "accuracy score for Knn classifier model is- 35.6\n"
     ]
    }
   ],
   "source": [
    "cv_score_best_knn=cross_val_score(knn,x,y,cv=11).mean()*100\n",
    "print(\"cross validation score is-\",cv_score_best_knn)\n",
    "print(\"accuracy score for Knn classifier model is-\",knn_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3e6f3209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       737\n",
      "         3.0       0.27      1.00      0.43       688\n",
      "         4.0       0.00      0.00      0.00       713\n",
      "         5.0       1.00      0.45      0.62       748\n",
      "\n",
      "    accuracy                           0.36      2886\n",
      "   macro avg       0.32      0.36      0.26      2886\n",
      "weighted avg       0.32      0.36      0.26      2886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468a2f9f",
   "metadata": {},
   "source": [
    "## Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3c26f70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Accuracy-  36.4\n",
      "\n",
      "Test Accuracy-  36.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=10,test_size=0.20)\n",
    "rf.fit(x_train,y_train)\n",
    "pred_train=rf.predict(x_train)\n",
    "pred_test=rf.predict(x_test)\n",
    "rf_train_acc=round(accuracy_score(y_train,pred_train)*100,1)\n",
    "rf_test_acc=round(accuracy_score(y_test,pred_test)*100,1)\n",
    "print(\"\\nTrain Accuracy- \",rf_train_acc)\n",
    "print(\"\\nTest Accuracy- \",rf_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "52c17043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation score is- 36.43986116114542\n",
      "accuracy score for Knn classifier model is- 36.6\n"
     ]
    }
   ],
   "source": [
    "cv_score_best_rf=cross_val_score(rf,x,y,cv=11).mean()*100\n",
    "print(\"cross validation score is-\",cv_score_best_rf)\n",
    "print(\"accuracy score for Knn classifier model is-\",rf_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a28caa84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         2.0       0.00      0.00      0.00       726\n",
      "         3.0       0.28      1.00      0.44       717\n",
      "         4.0       0.00      0.00      0.00       746\n",
      "         5.0       1.00      0.49      0.65       697\n",
      "\n",
      "    accuracy                           0.37      2886\n",
      "   macro avg       0.32      0.37      0.27      2886\n",
      "weighted avg       0.31      0.37      0.27      2886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6f96490a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.422235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>36.6</td>\n",
       "      <td>36.422235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Knn Classifier</td>\n",
       "      <td>35.6</td>\n",
       "      <td>36.370565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>36.6</td>\n",
       "      <td>36.439861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Models  Test Accuracy   CV Score\n",
       "0       Logistic Regression           36.0  36.422235\n",
       "1  Decision Tree Classifier           36.6  36.422235\n",
       "2            Knn Classifier           35.6  36.370565\n",
       "3  Random Forest Classifier           36.6  36.439861"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models=['Logistic Regression','Decision Tree Classifier','Knn Classifier','Random Forest Classifier']\n",
    "test_acc=[test_accuracy,dt_acc_test,knn_test_acc,rf_test_acc]\n",
    "cv=[cv_score_best,cv_score_best_dt,cv_score_best_knn,cv_score_best_rf]\n",
    "dfm=pd.DataFrame(list(zip(models,test_acc,cv)),columns=['Models','Test Accuracy','CV Score'])\n",
    "dfm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19460447",
   "metadata": {},
   "source": [
    "We would finalize Random Forest Classifier as our final model because it has highest accuracy and recall and f1-score is also highest for this model among all others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b000139",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "be3b6d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, max_features=6)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\":[100,200,300],\n",
    "    \"max_depth\":[10, 50, 100],\n",
    "    \"max_features\":[6,8,10,12,14,16],\n",
    "    'bootstrap': [True, False],\n",
    "    \"min_samples_split\": [2, 6, 10]\n",
    "}\n",
    "\n",
    "rf_reg = RandomForestClassifier()\n",
    "\n",
    "rf_reg_tuned = GridSearchCV(estimator=rf_reg,\n",
    "                            param_grid=param_grid,\n",
    "                            cv=3,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=2)\n",
    "\n",
    "rf_reg_tuned.fit(x_train, y_train)\n",
    "rf_reg_tuned.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "de2e82a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Accuracy-  36.6\n",
      "\n",
      "Test Accuracy-  36.0\n"
     ]
    }
   ],
   "source": [
    "rf1=RandomForestClassifier(max_depth=10, max_features=6,bootstrap=True)\n",
    "rf1.fit(x_train,y_train)\n",
    "pred_train=rf1.predict(x_train)\n",
    "pred_test=rf1.predict(x_test)\n",
    "train_acc=round(accuracy_score(y_train,pred_train)*100,1)\n",
    "test_acc=round(accuracy_score(y_test,pred_test)*100,1)\n",
    "print(\"\\nTrain Accuracy- \",train_acc)\n",
    "print(\"\\nTest Accuracy- \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddbfbc9",
   "metadata": {},
   "source": [
    "No change in accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426b4c50",
   "metadata": {},
   "source": [
    "## Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "401e6e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(rf, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
